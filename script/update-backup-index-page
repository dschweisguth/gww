#!/usr/bin/env ruby

# Regenerates the index.html in
# http://guesswherewatcher-backups.s3-website-us-west-2.amazonaws.com/
# from the list of other objects in that bucket

require 'date'
require 'open3'

class UpdateBackupIndexPage
  BUCKET = 's3://guesswherewatcher-backups'

  def run
    upload index_page links bucket_list
  end

  private

  def bucket_list
    stdout, stderr, status = Open3.capture3 "aws s3 ls #{BUCKET} --recursive"
    if !status.success?
      warn "Couldn't list bucket: #{stderr}"
      exit 1
    end
    stdout
  end

  def links(bucket_list)
    bucket_list.
      split("\n").
      map(&:split).
      reject { |fields| fields.last == 'index.html' }.
      map do |fields|
        [
	  Date.strptime("#{fields[0]} #{fields[1]}", "%Y-%m-%d %H:%M:%S"),
	  fields.last
	]
      end.
      sort_by { |date, object_name| date }.
      reverse.
      map do |_date, object_name|
        %Q(<a href="#{object_name}">#{object_name}</a>)
      end
  end

  def index_page(links)
    <<~HTML
      <!doctype html>
      <html>
      <head>
        <meta charset=utf-8>
        <title>Guess Where Watcher backups</title>
      </head>
      <body>
        #{links.join "<br/>\n"}
      </body>
      </html>
    HTML
  end

  def upload(index_page)
    output, status =
      Open3.capture2e(
        "aws s3 cp - #{BUCKET}/index.html --content-type text/html",
	stdin_data: index_page)
    if !status.success?
      warn "Couldn't upload index page: #{output}"
      exit 1
    end
  end

end
UpdateBackupIndexPage.new.run
